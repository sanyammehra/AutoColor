{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "\tinput_image = []\n",
    "\ti = 0\n",
    "\tfor filename in glob.iglob('../data/tiny-imagenet-200/train/**/*.JPEG',recursive=True):\n",
    "\t\timg = mpimg.imread(filename)\n",
    "\t\tif(img.shape == (64,64,3)):\n",
    "\t\t\tinput_image.append(list(mpimg.imread(filename)))\n",
    "\t\tif(i%10000 == 0):\n",
    "\t\t\tprint(i)\n",
    "\t\ti+=1\n",
    "\t\t#if(i>5000):\n",
    "\t\t#\tbreak\n",
    "\n",
    "\treturn np.asarray(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "(98179, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "image_data = read_data()\n",
    "print (image_data.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAG5hJREFUeJztnW3MZVV1x///gpQZRV7UTicMKTQSDR/qYCaI0RiEYqg1\n0g+GaE0zmknmi20wtRFok6Ym/aBffPnQmEwE5QMV8K0QYlScQpomDfJQUHkRQYphCDC2AbWd8QVd\n/XDPw5x77t3rrr3vPuc8T87/N7mZe87ZZ+11z737OWudtfbaNDMIIabF74ytgBBieDTwhZggGvhC\nTBANfCEmiAa+EBNEA1+ICaKBL8QEWWvgk7yC5KMkHyd5bS2lhBD9wtIEHpInAfghgMsBHAFwL4D3\nmdnD9dQTQvTByWucexGAx83sCQAgeTOAKwEkB/7OnTvs9NNfGRDNNdSqJWEooWJbUSHRtc9c2Z/+\n9Kc4duz4yl/qOgP/bABPtbaPAHiTd8Lpp78SH/zA+2cbHdXobLU3o2OPjLXMGstzetT/K1BFYltI\n6xcWvBwL57XlLfxgS37BXT0SfeXIrz2QzJNo7mZMfqGVbcmNE9zw+ZtCsnp/uEfyIMkNkhvHjh3v\nuzshRIB17vhPAzintb2n2TeHmR0CcAgAdu/eZZt/1bt3ZPeG1GobvuOv3LG5u8J91rVeqoisLsS/\n3svfs3uX8ayBKEyYKF093AOe2ZBq50mgdzDIfF82Z3314TPmfQPr3PHvBXA+yfNIngLgvQBuX0Oe\nEGIgiu/4ZvYiyb8E8E0AJwG4wcweqqaZEKI31jH1YWZfB/D1SroIIQZirYFfAjv/55xTq908Ob5R\n/rOGmLR+qCI/eHmiXveiuKLn4sm+3SfyDr6O0fOGLGqzXl9K2RVigmjgCzFBBjf1y6iRKRI5UkmP\ncPinMGOl2DCN6tFmfdO577M8CWW/nE4orlibtsy2vEKJFT0J3fGFmCAa+EJMEA18ISbIiD6+57Cs\nH5jr+mlpv7tC0Mv7KK5f5hx01Uqf139Icz18/er71oNG2Ob6rd9xzSc7uuMLMUE08IWYIFs0nOeZ\n6dHQk9NurlncaBq0DkdhxlwRUSF9m83OLMd0rl734MC2fUF3NUKOaUVi0nTHF2KCaOALMUFGmKRj\nL71Lt3GYq2jgndc1DhNSvQfrhUUXPI8jXn7Ee3Jf2emw2LUqn4TiPY8uqeZR5p71IL4SqQ6dEnSd\n7yxXZd3xhZggGvhCTBANfCEmyJYJ5xV5rY67uNjUIs18+SXkZO4lC4JmCQ3K8Fguv3wOX3Fq49K+\n+3jSMCZzehWGJnML3OiOL8QE0cAXYoJs0Uk6MRbMGksvudNv1l0N4xPxiR3B6JgnumiektNXWISr\nr+erBWOkPdjwUfHFaozgd+iOL8QE0cAXYoJo4AsxQUbw8Ven7K4vG3G/qXT11nQMpspHK6zDMb9C\nrttD+1oVBurCvmnUd49KS69LNyrOtS/7OXaT0Ot90JV3fJI3kDxK8sHWvrNI3knyseb/M6tpJITo\nnYip/wUAV3T2XQvgsJmdD+Bwsy2E2CasNPXN7N9IntvZfSWAS5r3NwK4G8A1WT0vmMcxc9OfmVYQ\nbClNKqttbiNnNmBt+raVo/L7Xv4q2NIthejNAa1NhvRMRUof7u0ys2ea988C2FUoRwgxAms/1Tcz\ng/P3huRBkhskN44dO75ud0KICpQ+1X+O5G4ze4bkbgBHUw3N7BCAQwCwe/eutEESfDQ7N9kmyzTO\nnwxSQ14WW+XpdJvK9fj6qDdngxYNHLjwYJg8vUrv+LcD2N+83w/gtkI5QogRiITzvgjgPwC8juQR\nkgcAfBzA5SQfA/DHzbYQYpsQear/vsShyyrrIoQYiOEz9zZ9+XB9/MJmhW5fsDK/S2nAJ7x8gCO+\ndkiQray+mpljL8l3tuLZbidabsXHJMB8GLC8aEl+sxTK1RdigmjgCzFBtnUhDo/4ylju4kyxvgrO\nWSnHrb3GJe82m9a4ri2ztH0hvSoaVeJ0zmSnGnOFqjBMuG1ZX1otVwixFhr4QkwQDXwhJsh4hTgs\nHbpxvahghYqMkvvzEtoz64IRR3MeKLjPGpzVntP+/rzQ0s/pEy1oUlD4JCatmsx5alydMqXKniSt\ntz6eh+74QkwQDXwhJsjgpv6JinuFhotjXUZzAaPFMcJl7p2GrqUfDFEthuxi53mMVfOj3FyNZr5V\n6H3h4uRfLX/9gJj/12dtft3xhZggGvhCTJCBTX07YRZnzSZZbsdUf4KdI3/OFk/P9Kkz0SfnYKtZ\njUlMlamR4FdhepdPVnhhuTYLn7NAsT6KlmyiO74QE0QDX4gJooEvxAQZL5znLTsVdKkWRdRN9eoW\nnkipGA3LdWV4rUvDedFmdJfNSnTeR3aee7TfIiBpnIIgpV9GUbZefw9idMcXYoJo4AsxQUYsxNHB\nzcirPRmkVZu/XMgJnHBejZhM8USc4iV385uFRWTIC5v3wdhntGu3X1eIowi9H/jy83Lcm023N3qO\n7vhCTBANfCEmiAa+EBNkWB/f0Kqr31cH6zYrmGnn5WNmuP9RwgmkpbP/CvotpU6K7YBhv2B1Fj/r\ntxMuDOfz1hs0kSW0ziF5F8mHST5E8upm/1kk7yT5WPP/mdW0EkL0SsTUfxHAR8zsAgAXA/gQyQsA\nXAvgsJmdD+Bwsy2E2AZE1s57BsAzzfufk3wEwNkArgRwSdPsRgB3A7gm3HOGuR01S/12JSZgzFb2\nw22FRTqcY7VZ1L9dL79C1Y+eycsGbPZW8rOK5nZ64d+5dulY8LqXPuvhHslzAVwI4B4Au5o/CgDw\nLIBda+oihBiI8MAn+QoAXwHwYTP7WfuYzZ5OLP0jRPIgyQ2SG8eOH19LWSFEHUIDn+TLMBv0N5nZ\nV5vdz5Hc3RzfDeDosnPN7JCZ7TOzfTt37KihsxBiTVb6+CQJ4HoAj5jZJ1uHbgewH8DHm/9vi3VZ\n0zEsLdjZ8pU6blS4JmLUd3cmIfbiJDO5Eca8Bxhrshi6ctbfS8roiqiQBz0v0DkUTaB2fh/RvjsN\n03NFQ93OEYnjvwXAXwD4PskHmn1/i9mAv5XkAQA/BnBVrEshxNhEnur/O9J/1i6rq44QYgiGn53X\nmC/WCVW4RTRScbqsooi+PvnnrdlvjvgOTF6Q+Y9TuzBJKeFwW2nkMPzTKVy6qkIxEv+0YPi0YlUU\n5eoLMUE08IWYIOMV4nCeWHpZd/OmrCPeSbGK12WPmVPeElqe/BrJY545X2XqR+mT9hJK0zLb3oKz\n/JU3gSfuSnTDQInMwIU90aWXW2+7mXvujz/v16Q7vhATRANfiAmigS/EBNk6xTYLwhPdLLAqNevn\nO8jWyet3lXgWRGvcPLKof+4c82pEVqfjoFvqm/ImtwVDvFmfxfti5q5P0I93ms3J8LIc1wxl644v\nxATRwBdigoyWueeaOwsTW2JmjDe5JDqVoiTbzauZlrUYeDAbMByODIYwvaN+eHP9ciHx8Gm9IhQA\n8pZpN6/vaNZdW543Vav9peUsyqBwnhBiBRr4QkwQDXwhJsiIy2RHWi1uzRfKyPH2gs8Jima3xVNB\nS2pGLMo8IWTRs0utw5bG/ZzuA4VoiMpRpELIsUxgWZq1m7Lrpfa25UVn4HnhvIXTFM4TQqxAA1+I\nCTKwqW/ot1hGOpyXch7iM/XSB7NCdl7hiUSCWJaOTHy2nCQwt4M12znn+TPaYvmW0SW08urqxzL3\n2uG3vKW2UyFBL5OxK1PhPCHECjTwhZgg49Xc65gx8WWnYrNGyuvNlcxKcaIQxYGHdLaYP7EopVVH\nRvAJdFJ4Bv5ZXnnt1ASb0u826t90T/PM7/ZGUKi3NJZX4M+dgWWd/310xxdigmjgCzFBNPCFmCAj\nFuLIcLKSvlNGkYuCggzhwh5u5KZw5l5ONCgp0/FNnVhflertqa69VEYnzJUsypGlUmkMNhimi874\nC1dg6RbbTG4stl3Byjs+yVNJfofkd0k+RPJjzf7zSN5D8nGSt5A8JatnIcRoREz9XwK41MzeAGAv\ngCtIXgzgEwA+ZWavBfA8gAP9qSmEqElk7TwD8L/N5sualwG4FMCfN/tvBPAPAD67sseXCnE4WUml\nYTrHFIobimkTPm2Q5bgt7bex8/IyA1My3FTG6KEyvK826rd4Zm44ShdsuGBhF0yqyah7P1/IxSvs\nUZxnukDo4R7Jk5qVco8CuBPAjwC8YGYvNk2OADg7q2chxGiEBr6Z/cbM9gLYA+AiAK+PdkDyIMkN\nkhvHjv2iUE0hRE2ywnlm9gKAuwC8GcAZJDddhT0Ank6cc8jM9pnZvp07T11LWSFEHVb6+CRfA+DX\nZvYCyR0ALsfswd5dAN4D4GYA+wHcFulw0xMJZmcuHPRdvRLvNMf3Xe6s5gVW8p1rfxJfNxQXLMQR\nzJR1r6gjIxniLK8+mtYpPDOt9Tty3eUMJdn+bUbr3neLeSTaLejh6Z8XzovE8XcDuJHkSZhZCLea\n2R0kHwZwM8l/BHA/gOuzehZCjEbkqf73AFy4ZP8TmPn7QohtxpZZJrtz0N0MHHDle6E9t55dUI+g\n1+IuBx4UseSYo39CSI3svMKJjPDryEXlR3uvMQuxE4ZOTsXMCL3NXcdgOC8rLrqIcvWFmCAa+EJM\nkGFNfcNLtpHzwLLcBA4WQmg//fcspnBmXaHZFT0tyx3J1qIvvLBBmxophO1JNGk1or7J4qHgMlle\nEY25ZsFvrTtIwq7EanTHF2KCaOALMUE08IWYICOG87xD3Wy0VMMcLzYae8qPUYX1DUiK711+bP2F\nq2tREuvzMto8cVG/e+XulJDgicHMOrcQR6Lfrow1n+Doji/EBNHAF2KCjLdabvLIknO8mTktGA7X\nxNqV1uaPhhUX+2vJaO/PCBfWD+EFzcuuuVoUeYpPmEr1vWgcxyZ4dc9KbcaLcnSPtePV3WuVmOhT\nQvCa6Y4vxATRwBdigmjgCzFBRgjnJUJWJSm7HV/a977yw3nxlNo6nnXq2UB8rlgfRGOaZam3848C\nCsN5wZmYc6m9OWnEXuPk+gTxZGpLP91xzlPKrhAiEw18ISbICMtkN/85loqbCVdY8SFtDeb0lW+K\nd2FhqC9FjRIUrkrRSXae/HC7YDgvulSVp4k3jS+nIGQyM7CwiEZyOa1OX1nrry+iO74QE0QDX4gJ\nsoUm6ayfudduWFriOtxXixzzvcRAW7Q886UUG4Ylc22ANczxlWos+fzRp+7BHhw3YNGyL3mS7/q5\nTrP0ZKHc71d3fCEmiAa+EBNEA1+ICTKwj2/w5ufNNfN3NLvjs9RKMvdyDtVhuY6l3Y5alKMkC7FG\nmM49FM3cc4S4WXwF7bp6eV+8F+rL/LbDd/xmqez7Sd7RbJ9H8h6Sj5O8heQpWT0LIUYjx9S/GsAj\nre1PAPiUmb0WwPMADtRUTAjRH6GBT3IPgD8F8LlmmwAuBfDlpsmNAP5slRxD29i3+dfcQVtofUKI\nnXi5Pcy/2qeZ+89TIyHb7bnzMnNebR2XfvossvQa6OXqa6h+Debkt7/lhc6839W8lPnvvvXP/Y21\nfwPdz9luFew67+AC0Tv+pwF8FMBvm+1XAXjBzF5sto8AODsoSwgxMisHPsl3AThqZveVdEDyIMkN\nkhvHj/+iRIQQojKRp/pvAfBuku8EcCqAVwL4DIAzSJ7c3PX3AHh62clmdgjAIQD4/V2vrmW1CSHW\nYOXAN7PrAFwHACQvAfA3ZvZ+kl8C8B4ANwPYD+C2UI/N0M8KpyT+XOQtyRb8mzNX+DBGN2XXO68k\nYLX4UWKataM/C6Xcg/3NtfPqQnidt0/pnuNMh5yLjjld1UgPnpPvKRleezxj3TvnUFy+d94i6yTw\nXAPgr0k+jpnPf/0asoQQA5KVwGNmdwO4u3n/BICL6qskhOibbTE7L3UsXLihQ1lhj3TbCiKagyeO\n1si6KyyDl26X9UHDjlKs7+K+hltCK7i6lpu5N/9ZPHO++9vnsr1JlKsvxATRwBdigoxn6ntGSZEd\nmtFzBfnFpniw860S96w90ceLUHQn6dS5BgnT2XM1nSjBYnZdQmZOzb30ctCdzQoFEBt0xxdigmjg\nCzFBNPCFmCAjLJM981uKSy44PrLrISZPKwvG9eGDx69JONUrKCN9yCoXzfRwlxevokcf31+F78Ji\nzxeS3RZ0rTu+EBNEA1+ICTJaOM9P3CszxOIiHHehhg1YuExW/Ky0Xcek6em4PuHZTvXN/rKJUOmM\ntiomfMYknbAH6UzS8SrpRcldsVl3fCEmiAa+EBNEA1+ICTLaMtlbRrgb9YsW70gfGrq2fYn+DGrp\nFoNcOFQvvXSp+OjBlAMd9dVX9VX7s7mPVNIHcx8r6Y4vxATRwBdigow4O69Lhdl6W4bEkkgYwvQP\n9lAUAsvQPmhil5FReKNC8ZSwKlXq6g2D7vhCTBANfCEmyAiTdPIJZzaVPF13S0bn1JOOdbBymaRM\nicUPmb2JISWmqHdOzsLIRYxnO6f0L9eoXgltD93xhZggGvhCTBANfCEmyNYstrnQMt8TDHvnnQPR\nco9z0ZmFzvqNP3oFK/Lqxc/oLgFWknU3ZuZbVngvcIbfOprlGNGiRJccLdKEBj7JJwH8HMBvALxo\nZvtIngXgFgDnAngSwFVm9vya+gghBiDH1H+7me01s33N9rUADpvZ+QAON9tCiG3AOqb+lQAuad7f\niNmaetesPi1g2FSwlEtFVKnD0TLEFk2y9ScSxeNj0Rr+PYTDKqxd4LpT24zazt9iRmjeBYre8Q3A\nt0jeR/Jgs2+XmT3TvH8WwK6snoUQoxG947/VzJ4m+XsA7iT5g/ZBMzNyedGq5g/FQQA47bSXr6Ws\nEKIOoTu+mT3d/H8UwNcwWx77OZK7AaD5/2ji3ENmts/M9u3ccWodrYUQa7Fy4JN8OcnTNt8DeAeA\nBwHcDmB/02w/gNvW0sRar0UtWq/EOVlOVEKe285fzjmlRvfYfLuY/IVm3it5oneso1n08nikZDj6\nLlyfVjvvOs6/2Hmlrn0fBC9cD8rkioqY+rsAfK1Z0PBkAP9sZt8geS+AW0keAPBjAFflKiuEGIeV\nA9/MngDwhiX7/wfAZX0oJYTol61TiMOdgpcwYmpMnhucdJGOfAk5SYKdWu5MHysqGuGlqnlFP7ZF\nmG6FG5ZNjfTF9S6ccvWFmCAa+EJMEA18ISbI1vHxtwUpv8qZ4tfDc4caRYKqqzWor95HZ6UyS6ZD\njv9gQ3d8ISaIBr4QE2S0Ypt5xk7Udi6wsbtmVzg+VsNY7iEeWaOe/fiW6BLy1wuo1LBz2la5OOuF\nBHXHF2KCaOALMUG24VN9x5yfO1RoRoe9hWAVNUeNRWMtGDWIUsUqLXGzeqa4q3bWZIb4ov5Ka+JH\nGypzTwiRiQa+EBNEA1+ICTKaj+8GI8LuudPQc9TcgpReTXnHQU/qlX4O4XppbnreSCyEPr22Be3i\nipSc5EtwRZZk5+Wf0ouMBLrjCzFBNPCFmCDbMJznEbQv3SIUQbt07rTOOTXMdE9+30Qz/qpEnkZy\nY+rE7NY4r0RGvWulO74QE0QDX4gJooEvxAQZzcdfTE+N+uSxU8IptQunOecl/f+c9MxoSDAssD5b\nJHo4R/g5QS/rcKfljRSOXBfd8YWYIBr4QkyQEUz9lJlTYJoXWvPFRfHabkDBctQLfYf1z9Exv1m8\nNn8Go5nAPcioPssx2izece5XGLrjkzyD5JdJ/oDkIyTfTPIskneSfKz5/8zMvoUQIxE19T8D4Btm\n9nrMltN6BMC1AA6b2fkADjfbQohtwEpTn+TpAN4G4AMAYGa/AvArklcCuKRpdiOAuwFcE+04zzju\ns1516dN/R4Z5qW8FBUEyTL6ixZgKV9AqabfQd7BdnNq1+bZO36UlFJcRueOfB+AnAD5P8n6Sn2uW\ny95lZs80bZ7FbFVdIcQ2IDLwTwbwRgCfNbMLAfwfOma9maVXticPktwguXHs+C/W1VcIUYHIwD8C\n4IiZ3dNsfxmzPwTPkdwNAM3/R5edbGaHzGyfme3buePUGjoLIdZkpY9vZs+SfIrk68zsUQCXAXi4\nee0H8PHm/9tCPW76v8X1yWv45LFTyv1zL/uv5HPP95suyllKV36Czuei9ywjOJHRi26mpA+/Gnrf\nhThijWteg2gc/68A3ETyFABPAPggZtbCrSQPAPgxgKvW1EUIMRChgW9mDwDYt+TQZXXVEUIMwTZZ\nQitKtKBd+5S00bRgeobN9AKXwz3U86SO7ucKX7t+TeAy03Y7TGiKndSnS6NcfSEmiAa+EBNEA1+I\nCbKFZueNBZ2tTpgr7HRutc+4Am/9gPCJ/RbAqB7AHDNl16E42TvzgYDu+EJMEA18ISYIrZcqDInO\nyJ9gluzzagD/PVjHy9kKOgDSo4v0mCdXjz8ws9esajTowH+pU3LDzJYlBE1KB+khPcbSQ6a+EBNE\nA1+ICTLWwD80Ur9ttoIOgPToIj3m6UWPUXx8IcS4yNQXYoIMOvBJXkHyUZKPkxysKi/JG0geJflg\na9/g5cFJnkPyLpIPk3yI5NVj6ELyVJLfIfndRo+PNfvPI3lP8/3c0tRf6B2SJzX1HO8YSw+ST5L8\nPskHSG40+8b4jQxSyn6wgU/yJAD/BOBPAFwA4H0kLxio+y8AuKKzb4zy4C8C+IiZXQDgYgAfaq7B\n0Lr8EsClZvYGAHsBXEHyYgCfAPApM3stgOcBHOhZj02uxqxk+yZj6fF2M9vbCp+N8RsZppS9mQ3y\nAvBmAN9sbV8H4LoB+z8XwIOt7UcB7G7e7wbw6FC6tHS4DcDlY+oCYCeA/wTwJswSRU5e9n312P+e\n5sd8KYA7MEtRH0OPJwG8urNv0O8FwOkA/gvNs7c+9RjS1D8bwFOt7SPNvrEYtTw4yXMBXAjgnjF0\naczrBzArknongB8BeMHMXmyaDPX9fBrARwH8ttl+1Uh6GIBvkbyP5MFm39Dfy2Cl7PVwD3558D4g\n+QoAXwHwYTP72Ri6mNlvzGwvZnfciwC8vu8+u5B8F4CjZnbf0H0v4a1m9kbMXNEPkXxb++BA38ta\npexzGHLgPw3gnNb2nmbfWITKg9eG5MswG/Q3mdlXx9QFAMzsBQB3YWZSn0Fyc6r2EN/PWwC8m+ST\nAG7GzNz/zAh6wMyebv4/CuBrmP0xHPp7WauUfQ5DDvx7AZzfPLE9BcB7Adw+YP9dbsesLDiQUx58\nDUgSwPUAHjGzT46lC8nXkDyjeb8Ds+cMj2D2B+A9Q+lhZteZ2R4zOxez38O/mtn7h9aD5MtJnrb5\nHsA7ADyIgb8XM3sWwFMkX9fs2ixlX1+Pvh+adB5SvBPADzHzJ/9uwH6/COAZAL/G7K/qAcx8ycMA\nHgPwbQBnDaDHWzEz074H4IHm9c6hdQHwRwDub/R4EMDfN/v/EMB3ADwO4EsAfnfA7+gSAHeMoUfT\n33eb10Obv82RfiN7AWw0382/ADizDz2UuSfEBNHDPSEmiAa+EBNEA1+ICaKBL8QE0cAXYoJo4Asx\nQTTwhZggGvhCTJD/B97/jB6zJLoJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10aa16eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "mean_image = np.mean(image_data,axis = 0,dtype = 'float32')\n",
    "print (\"Here\")\n",
    "image_data = image_data- mean_image\n",
    "plt.imshow(mean_image.astype('uint8'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Converting RGB TO GRAYSCALE DEMO MODEL\n",
    "\n",
    "def simple_rgb_to_gray(X,Y):\n",
    "\tWconv1 = tf.get_variable(\"Wconv1\", shape=[1, 1, 3, 1])\n",
    "\tbconv1 = tf.get_variable(\"bconv1\", shape=[1])\n",
    "\ty_out = tf.nn.conv2d(X, Wconv1, strides=[1,1,1,1], padding='SAME')\n",
    "\t#y_out = y_out[:,:,:,0]\n",
    "\treturn y_out\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    a = np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "    return a[:,:,:,np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.29879e+09\n",
      "3.42741e+07\n",
      "199325.0\n",
      "358.674\n",
      "3.52261\n",
      "0.0160818\n",
      "0.000889551\n",
      "6.18149e-06\n",
      "2.14312e-06\n",
      "1.68693e-06\n",
      "1.98715e-06\n",
      "2.18504e-06\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, [None, 64, 64, 3])\n",
    "Y = tf.placeholder(tf.float32 ,[None , 64,64,1])\n",
    "y_out = simple_rgb_to_gray(X,Y)\n",
    "loss = tf.nn.l2_loss(y_out - Y)\n",
    "optimiser = tf.train.AdamOptimizer(0.4)\n",
    "train_step = optimiser.minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "for i in range(600):\n",
    "    \n",
    "\tfeed_dict = {X: image_data[i*100:100*i+100], Y: rgb2gray(image_data[i*100:i*100+100])}\n",
    "\tlosses,_ = sess.run([loss,train_step],feed_dict)\n",
    "\tif(i%50 ==0):\n",
    "\t\tprint (losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wconv1:0', 'bconv1:0']\n",
      "[[[[ 0.29900002]\n",
      "   [ 0.58699995]\n",
      "   [ 0.11400003]]]]\n",
      "Observe that weights are close to [0.299,0.587,0.114] , hence it learns rgb to gray conversion\n"
     ]
    }
   ],
   "source": [
    "var  = tf.trainable_variables()\n",
    "var = [v.name for v in tf.trainable_variables() ]\n",
    "print (var)\n",
    "numpy_val = sess.run([var[0]])\n",
    "weights = np.asarray(numpy_val[0])\n",
    "print (weights)\n",
    "\n",
    "print (\"Observe that weights are close to [0.299,0.587,0.114] , hence it learns rgb to gray conversion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baselinish(X,Y,is_training):\n",
    "    \n",
    "    W_conv = tf.get_variable(\"Wconv\",shape = [3,3,1,32])\n",
    "    b_conv = tf.get_variable(\"bconv\",shape = [32])\n",
    "    a1 = tf.nn.conv2d(X, W_conv, strides=[1,1,1,1], padding='SAME') + b_conv\n",
    "    a1 = tf.nn.relu(a1)\n",
    "    #a1 = tf.contrib.layers.batch_norm(a1,center = True, scale = True, is_training = is_training,scope = 'bn1')\n",
    "    #a1 = tf.nn.max_pool(a1,ksize = [1,2,2,1],strides = [1,2,2,1],padding = 'VALID')\n",
    "    \n",
    "    W_conv2 = tf.get_variable(\"Wconv2\",shape = [3,3,32,64])\n",
    "    b_conv2 = tf.get_variable(\"bconv2\",shape = [64])\n",
    "    a1 = tf.nn.conv2d(a1, W_conv2, strides=[1,1,1,1], padding='SAME') + b_conv2\n",
    "    a1 = tf.nn.relu(a1)\n",
    "    #a1 = tf.contrib.layers.batch_norm(a1,center = True, scale = True, is_training = is_training,scope = 'bn2')\n",
    "    \n",
    "    W_conv3 = tf.get_variable(\"Wconv3\",shape = [3,3,64,3])\n",
    "    b_conv3 = tf.get_variable(\"bconv3\",shape = [3])\n",
    "    a1 = tf.nn.conv2d(a1, W_conv3, strides=[1,1,1,1], padding='SAME') + b_conv3\n",
    "    \n",
    "    return a1\n",
    "    \n",
    "    #a1 = tf.nn.relu(a1)\n",
    "    #a1 = tf.contrib.layers.batch_norm(a1,center = True, scale = True, is_training = is_training,scope = 'bn3')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.82477e+09\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, [None, 64, 64,1])\n",
    "Y = tf.placeholder(tf.float32 ,[None , 64,64,3])\n",
    "is_training = True;\n",
    "y_out = baselinish(X,Y,is_training)\n",
    "loss = tf.nn.l2_loss(y_out - Y)\n",
    "optimiser = tf.train.AdamOptimizer(0.1)\n",
    "train_step = optimiser.minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    \n",
    "\tfeed_dict = {Y: image_data[i*100:100*i+100], X: rgb2gray(image_data[i*100:i*100+100])}\n",
    "\tlosses,_ = sess.run([loss,train_step],feed_dict)\n",
    "\tif(i%5 ==0):\n",
    "\t\tprint (losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11436e+09\n",
      "8.53017e+08\n",
      "4.20555e+08\n",
      "3.62706e+08\n",
      "3.05249e+08\n",
      "3.15915e+08\n",
      "2.32528e+08\n",
      "3.86798e+08\n",
      "2.72259e+08\n",
      "2.19203e+08\n",
      "3.26696e+08\n",
      "2.43652e+08\n",
      "1.70487e+08\n",
      "2.21264e+09\n",
      "9.32889e+08\n",
      "6.44976e+08\n",
      "3.43498e+08\n",
      "3.82208e+08\n",
      "5.84535e+08\n",
      "4.65194e+08\n",
      "2.42241e+08\n",
      "2.81215e+08\n",
      "3.12711e+08\n",
      "1.07634e+09\n",
      "8.40695e+08\n",
      "3.66514e+08\n",
      "2.97062e+08\n",
      "3.07445e+08\n",
      "2.42532e+08\n",
      "2.1803e+08\n",
      "1.97032e+08\n",
      "1.92416e+08\n",
      "1.7182e+08\n",
      "1.36665e+08\n",
      "2.23089e+08\n",
      "2.45123e+08\n",
      "6.01583e+08\n",
      "6.76351e+08\n",
      "8.45727e+08\n",
      "4.71946e+08\n",
      "3.90021e+08\n",
      "3.38588e+08\n",
      "3.86434e+08\n",
      "4.10379e+08\n",
      "5.85703e+08\n",
      "6.93059e+08\n",
      "6.12982e+08\n",
      "4.26819e+08\n",
      "2.00008e+08\n",
      "2.29568e+08\n",
      "2.39413e+08\n",
      "1.74989e+08\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, [None, 64, 64,1])\n",
    "Y = tf.placeholder(tf.float32 ,[None , 64,64,3])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "with tf.variable_scope(\"model\") as scope:\n",
    "    train_model = baselinish(X,Y,is_training)\n",
    "    loss = tf.nn.l2_loss(train_model-Y)\n",
    "    optimiser = tf.train.AdamOptimizer(0.01)\n",
    "    train_step = optimiser.minimize(loss)\n",
    "\n",
    "    scope.reuse_variables()\n",
    "    test_model = baselinish(X,Y,is_training)\n",
    "    loss_test = tf.nn.l2_loss(test_model - Y)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "X_small_train = image_data[0:60000]\n",
    "X_small_test = image_data[60000:70000]\n",
    "\n",
    "def train_epoch(data):\n",
    "    sizee = data.shape[0]\n",
    "    batch_size = 100\n",
    "    for i in range(sizee//batch_size):\n",
    "        feed_dict = {Y: data[i*batch_size:batch_size*i+batch_size], X: rgb2gray(data[i*batch_size:batch_size*i+batch_size]),is_training:True}\n",
    "        losses,_ = sess.run([loss,train_step],feed_dict)\n",
    "        if(i%5==0):\n",
    "            print (losses)\n",
    "\n",
    "  \n",
    "\n",
    "def val_result(data):\n",
    "    sizee = data.shape[0]\n",
    "    batch_size = 100\n",
    "    for i in range(sizee//batch_size):\n",
    "        feed_dict = {Y: data[i*batch_size:batch_size*i+batch_size], X: rgb2gray(data[i*batch_size:batch_size*i+batch_size]),is_training:False}\n",
    "        losses = sess.run([loss_test],feed_dict)\n",
    "        if(i%5 ==0):\n",
    "            print (losses)\n",
    "\n",
    "num_epochs = 2\n",
    "for i in range(num_epochs):\n",
    "    train_epoch(X_small_train)\n",
    "    val_result(X_small_test)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Image visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rnd\n",
    "\n",
    "def rgb2gray2(rgb):\n",
    "    a = np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "    return a\n",
    "\n",
    "rand_indices = np.random.choice(2000,10)\n",
    "sample_images = X_small_train[rand_indices]\n",
    "print (sample_images.shape)\n",
    "grayed_sample_images = rgb2gray2(sample_images)\n",
    "print (grayed_sample_images.shape)\n",
    "\n",
    "feed_dict = {X:grayed_sample_images[:,:,:,np.newaxis],Y:sample_images,is_training:True}\n",
    "model_generated_images = sess.run([test_model,loss_test],feed_dict)\n",
    "print (model_generated_images[1])\n",
    "print(model_generated_images[0].shape)\n",
    "\n",
    "def show_images(images,gray = False):\n",
    "\n",
    "    \n",
    "    if(gray):\n",
    "        plt.subplot(221)\n",
    "        plt.imshow(images[0],cmap = plt.get_cmap('gray'))\n",
    "        plt.subplot(222)\n",
    "        plt.imshow(images[1], cmap = plt.get_cmap('gray'))\n",
    "        plt.subplot(223)\n",
    "        plt.imshow(images[2], cmap = plt.get_cmap('gray'))\n",
    "        plt.subplot(224)\n",
    "        plt.imshow(images[3], cmap = plt.get_cmap('gray'))\n",
    "    else :\n",
    "        plt.subplot(221)\n",
    "        plt.imshow(images[0]);\n",
    "        plt.subplot(222)\n",
    "        plt.imshow(images[1])\n",
    "        plt.subplot(223)\n",
    "        plt.imshow(images[2])\n",
    "        plt.subplot(224)\n",
    "        plt.imshow(images[3])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "show_images((sample_images+mean_image))\n",
    "show_images(grayed_sample_images + mean_image,gray = True)\n",
    "show_images(model_generated_images[0] + mean_image)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
